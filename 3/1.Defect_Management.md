# *Defect Management*

Defect Management is the workflow that handles defects. However, an apparent defect might for example be a false positive or a misunderstanding. Therefore, they are treated as ***anomalies*** within defect management. Defect Management starts with logging the anomalies in a ***defect report***, followed by analysis and classification. After classification there is the question of what to do about it, and once that is decided the report can be closed; By now it is out of the test team's hands.

## *Defect Reports*

Defect reports typically aim to provide sufficient information to defect management, including a means of tracking the context for the observed anomaly. It is also common to want defect reports to include ideas for how the development and test processes could be improved.

Therefore, a typical defect report from dynamic testing includes:
* A Unique ID (for *[configuration management](/0/1.Core_Concepts.md#configuration-management)*)
* A Title that summarizes the anomaly
* Date of observation, issuing organization and report author + role
* Identification for test object and test environment
* Anomaly context (test case, activity, test data, development phase, etc.)
* A sufficient description to reproduce the anomaly + any relevant recorded data
* Expectations and actual results
* Severity/impact of defect
* Priority
* Defect status
* References

With supporting tools, much of this can be included automatically. You can also use online templates.

Continue to *[test completion](/3/2.Test_Completion.md)*