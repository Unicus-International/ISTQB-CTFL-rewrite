# *Test Scope*

A test scope outlines what will be tested and what will not, it covers the constraints around the testing, the purpose of the test, and what the testers have at their disposal, including tools, estimates and documentation of relevant, earlier tests. With this, the test scope directs attention towards the purpose of the test.

## *Entry criteria/Definition of Done*

Entry criteria are things that should be in place before you start doing something. Entry criteria do not *have* to be met, but if they are not met they will make it harder, possibly to the point where it is not worth starting. For example, you will want to ensure that you have an available and appropriate testing environment before you start. Entry criteria are known as a Definition of Ready (to start) in some contexts. Both entry criteria and ***[exit criteria](/1/1/2.Test_Scope.md#exit-criteriadefinition-of-done)*** can be thought of as checklists.

## *Exit criteria/Definition of Done*

Exit criteria are an outline of at what point the activity is done. Therefore it is also known a *Definition of Done*. Typically a test's exit criteria include both measures of thoroughness (such as having achieved the desired level of coverage) and completion criteria (such as having reported all found defects). You should have clear exit criteria at each *[test level](/0/3.Test_LifeCycle.md#nested-tlcs-test-levels)*. It is worth remembering that "running out of time" is a valid exit criterion, provided the people who run the risk in case of a failure are aware of the situation and give the go-ahead anyway.

## *Test objectives*

Test objectives specify exactly which functions of [testing](/0/1.Core_Concepts.md#testing) the current test aims to achieve.
Typically, it will be one or more of the following, but even more specific:
* Evaluate work products.
* Trigger [failures](/0/1.Core_Concepts.md#failures).
* Ensure required coverage of the test object.
* Reduce the level of risk from poor software quality.
* [Verifying](/0//1.Core_Concepts.md#verification) that requirements are fulfilled.
* [Validating](/0//1.Core_Concepts.md#validation) that the test object is complete and works as expected.
* Building confidence in the test object's quality.

The details depend on the context detailed in the Test Scope and the overall Test Plan.

## *Test constraints*

Test constraints are exactly what they sound like: Various limitations on the scope of testing. They can be budget-related, deadlines or platform-related. It can be a constraint that the team lacks expertise on that prevents the testers from doing what would otherwise be either preferred or optimal (or both!). If it makes a difference, and especially if it requires a deviation from best practices or ideal solutions, it is worth including as a test constraint.

## *Test Basis*

The test basis covers the rest of what you will want in a test scope, including various known requirements and specifications (such as test coverage criteria), relevant information about the structure of the test object and its context, including things like previous test results, previous risk analyses and estimates.

Continue to *[test assumptions](/1/1/3.Test_Assumptions.md)*