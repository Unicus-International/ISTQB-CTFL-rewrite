# **Test Approach**

A test approach is, simply put, how you go about testing in your TLC. It covers the main contents of your test plan, from the relevant test levels, the different types of tests you will be performing, what work products (remember: the plan is itself a work product, as is everything else you make during the TLC) you will make along the way, the preconditions you need for your test, what it would take for the test to be considered done and what metrics you will collect. If you deviate from policy or typical strategies the approach should also cover those deviations.

## *Entry criteria/Definition of Done*

Entry criteria are things that should be in place before you start doing something. Entry criteria do not *have* to be met, but if they are not met they will make it harder, possibly to the point where it is not worth starting. For example, you will want to ensure that you have an available and appropriate testing environment before you start. Entry criteria are known as a Definition of Ready (to start) in some contexts. Both entry criteria and ***[exit criteria](/1/1/6.Test_Approach.md#exit-criteriadefinition-of-done)*** can be thought of as checklists.

## *Exit criteria/Definition of Done*

Exit criteria are an outline of at what point the activity is done. Therefore it is also known a *Definition of Done*. Typically a test's exit criteria include both measures of thoroughness (such as having achieved the desired level of coverage) and completion criteria (such as having reported all found defects). You should have clear exit criteria at each *[test level](/0/4.Test_LifeCycle.md#nested-tlcs-test-levels)*. It is worth remembering that "running out of time" is a valid exit criterion, provided the people who run the risk in case of a failure are aware of the situation and give the go-ahead anyway.

## *Strategy*

Here are some aspects of test strategy that are worth mentioning:

* **Automation**:
  Will you make use of automation? For what, and how extensively?
* **Test Techniques**:
  What kinds of tests will you employ? For what, and why?
* **Change of plans**:
  How will you go about changing plans if that becomes necessary?
* **Data Management**:
  How/where do you store the data you collect and produce?

## *Testing Quadrants

Testing quadrants are a way to group different test levels with best practices and more which can be a helpful tool for thinking about testing in your test approach. It was designed with iterative SDLCs in mind (as you see in *[DevOps](/0/1.Core_Concepts.md#devops)*, ++), and has particular advice for those. It organizes tests in quadrants based on whether a test is technology or business-facing, and whether it supports the team or critiques the product.

* **Q1/Technology-facing & supports the team**:
  *[Component tests](/0/4.Test_LifeCycle.md#component-testing)* and *[component integration tests](/0/4.Test_LifeCycle.md#component-integration-testing). Iterative: Q1 should be automated.
* **Q2/Business-facing & supports the team**:
  *[User story](/0/1.Core_Concepts.md#user-story)* related and functional tests, prototypes, simulations, etc. These tests check *[acceptance criteria](/0/1.Core_Concepts.md#acceptance-criteria)* as a guideline during development. Iterative: Q2 can be manual or automated.
* **Q3/Business-facing & critiques the product**:
  *[Exploratory testing](/1/4/2/3.Experience_Based_Testing.md#exploratory-testing)*, usability tests and *[user acceptance testing](/0/4.Test_LifeCycle.md#acceptance-testing)*. Iterative: Usually manual (since they are user-oriented).
* **Q4/Technology-facing & critiques the product**:
  Smoke tests and non-functional tests (performance, etc.). Iterative: Usually automated.

Continue to *[schedule](/1/1/7.Test_Schedule.md)*